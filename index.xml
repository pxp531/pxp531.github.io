<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pxxp</title>
    <link>https://pxp531.github.io/</link>
    <description>Recent content on pxxp</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 03 Sep 2024 21:09:59 +0800</lastBuildDate>
    <atom:link href="https://pxp531.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Perf原理01</title>
      <link>https://pxp531.github.io/posts/perf%E5%8E%9F%E7%90%8601/</link>
      <pubDate>Tue, 03 Sep 2024 21:09:59 +0800</pubDate>
      <guid>https://pxp531.github.io/posts/perf%E5%8E%9F%E7%90%8601/</guid>
      <description>| 看完前一节《perf基础使用》以后会对perf命令有些基础印象，现在这一章主要梳理一些概念，方便后续了解具体原理。&#xA;概念梳理 火焰图是perf record得到的perf.data文件再做perf.script得到的 perf是前端工具，我们用的命令行叫做perf perf_events是内核子系统，我们平时说的perf是指这个大的概念 perf_event是数据结构 event是数据源，包括硬件数据源、软件数据源、kprobe、tracepoint等 perf_events子系统 perf 这个就是上章节介绍的perf基础使用里面的各种命令，相当于这个子系统的前端。 perf_event_open perf_event_open()是系统调用，前端perf命令发出以后，走这个系统调用，连接前端和后端的桥梁。 perf_event_open对系统中打开的event分配一个对应的perf_event数据结构，所有对event的操作都是围绕perf_event展开的。 perf_event_open()系统调用返回一个文件描述符。 event 先讲这个，再讲perf_event可能会好理解一点 event就是我们要采集的数据源，比如CPU分支预测失败的硬件数据，或者page-fault的软件数据，又或者是block_getrq()类的tracepoint。 perf stat -e xxx;这个xxx就是接的数据源，我们的采集对象。 perf_event数据结构 perf采样拿到的event最终会放到perf_event数据结构里面，起存储作用。 perf_event的重要成员 struct perf_event_attr; struct perf_event_context; struct pmu; 数据传输 perf stat和perf record的数据传输是不一样的，传输对象和手段都不一样。stat走的read，record走的mmap。&#xA;perf_read：计数事件是用于对发生的事件总数进行计数的事件。通常，计数事件结果是通过 read（） 系统调用读取收集的 perf_mmap：采样事件定期将测量值写入缓冲区，然后可以通过mmap访问该缓冲区。 </description>
    </item>
    <item>
      <title>perf基础使用</title>
      <link>https://pxp531.github.io/posts/perf%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sun, 01 Sep 2024 16:36:54 +0800</pubDate>
      <guid>https://pxp531.github.io/posts/perf%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/</guid>
      <description>perf基础使用 | 书接上回《初识eBPF》，后面会按照perf -&amp;gt; ftrace -&amp;gt; kprobe -&amp;gt; eBPF来展开，这篇以perf基础使用开头&#xA;常用命令 perf list [列出事件类型，如硬件事件、软件事件等]&#xA;perf record [运行一个命令并把它的剖析记录到perf.data中]&#xA;perf report [读perf.data并显示剖析] perf script [读perf.data并显示跟踪输出] perf stat [收集性能计数器统计信息]&#xA;perf trace [实时跟踪]&#xA;perf probe [定义新的动态tracepoint]&#xA;列出事件 perf list：列出所有事件&#xA;perf list &amp;lsquo;sched:*&amp;rsquo;：列出sched tracepoint&#xA;perf list block：列出所有名称中带有字符串block的事件&#xA;-这个看起来是匹配，和第二个有啥区别&#xA;perf probe -l：列出当前可用的动态查看器&#xA;计数事件 perf stat -a sleep 5：-a是统计所有cpu，sleep 5是持续5秒 record perf record -p PID -F 99 -a -g sleep 10 主要参数 p PID是目标进程 F 99是采样频率 a 是所有CPU g 是栈指针 sleep 10是持续10秒 其他参数 &amp;ndash;cgroup=docker/xxx tracepoint tracepoint是内核预留的hook点，那么说明这个点数量不会多</description>
    </item>
    <item>
      <title>初识eBPF</title>
      <link>https://pxp531.github.io/posts/%E5%88%9D%E8%AF%86ebpf/</link>
      <pubDate>Fri, 30 Aug 2024 23:05:11 +0800</pubDate>
      <guid>https://pxp531.github.io/posts/%E5%88%9D%E8%AF%86ebpf/</guid>
      <description>| 在工作里面用了一些eBPF的内容，抽时间总结和归纳一下&#xA;初识 eBPF eBPF 是由 BPF 发展来的，一开始使用在网络，现在还可以用在可观测性、安全等多个领域 eBPF 可以在不修改内核源码或者重新编译内核源码的情况下，对内核功能进行扩展。 对比 ko 技术，ko 需要重新编译内核，且不安全；eBPF 无需重新编译，且有verify来保证安全性，比如死循环或者非法内存访问 通过 DAG 深度优先算法来遍历 BPF 程序的代码路径，确保没有环路发生； 逐条分析 BPF 每条指令的运行，对 register 和对 stack 的影响，最坏情况下是否有越界行为 eBPF 如何保证安全 限制代码数量 &amp;amp; 总运行步数 禁止循环 verifier 必须保证 BPF 程序的所有操作必须在有限时间内完成。所以不能用循环，用循环会直接拒绝。 虽然可以采用#pragma unroll 让编译器将循环展开，如果循环次数比较多，比如说100，展开以后会多了100条指令。而verifier有指令总数限制。不过到了新版本内核支持的指令数多了，展开也还好。 限制作用域，不允许访问全局变量；如果要访问全局变量，只能借助map &amp;hellip; eBPF 本质 本质上是想解决内核的可编程性。”eBPF之于Linux内核就同于lua至于Nginx，都提高了可编程性和降低了门槛“。 类似于Java里面的AOP思想。 为什么需要 eBPF 对性能的追求。 比如k8s中的iptables可以搞定容器网络通信，iptables是基于链表的，所以等k8s规模上来以后性能就下来了，是O(N)的一个复杂度。ipvs是基于哈希表性能会更好点，但是集群规模越来越大性能会有瓶颈。 对内核功能扩展 比如可观测性、安全等 eBPF 流程 内核中实现了一个cBPF/eBPF虚拟机； 【第一步：编译BPF C代码】 用户态可以用 C 来写运行的代码，再通过一个 Clang&amp;amp;LLVM 的编译器将 C 代码编译成 BPF 目标码； 【第二步：加载 BPF 目标码】 用户态通过系统调用bpf()将BPF目标码注入到内核当中； 【第三步：绑定、运行】 内核通过JIT(Just-In-Time)将BPF目编码转换成本地指令码；如果当前架构不支持JIT转换内核则会使用一个解析器(interpreter)来模拟运行，这种运行效率较低； eBPF 工具 BCC bpftrace libbpf libbpfgo aya [rust] eBPF缺点 门槛不低。虽然使用BCC、bpftrace写个小工具相对简单，但想要更进一步，还是需要对操作系统原理、内核有足够的了解。 【内核跟踪点】比如要对io某些点进行hook，比如io协议栈的每阶段的延时，就需要了解io协议栈，以及每阶段的出入口，所以难度还是不小的。 【用户态跟踪点】如果要跟踪用户态程序呢？需要从对应的二进制文件中查找对应的调试信息。 如果是编译类型语言，比如C会被编译成ELF格式的二进制文件就会保存相关信息。 如果是Java这种JIT类型的语言，就无法直接从二进制文件中获取应用程序的调试信息门槛就更高了。 不同的内核版本之前的差别，会导致某个内核版本上编写的eBPF程序没法在另一个内核版本上运行，虽然有CO-RE 但是还有一段距离。 其他 讲了这些以后，是不是可以上手eBPF了呢？答案不是的，如果有基础的人可以学习eBPF了，如果是新手的话可能还要学一些其他的，不然就容易云里雾里。接下来我会根据perf -&amp;gt; ftrace -&amp;gt; kprobe -&amp;gt; eBPF (BCC -&amp;gt; libbpf -&amp;gt; eBPF原理）来展开讲。 </description>
    </item>
  </channel>
</rss>
